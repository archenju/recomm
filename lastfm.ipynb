{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sophisticated-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "crucial-latest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id              name  userID  artistID  playCount\n",
      "0          1      MALICE MIZER      34         1        212\n",
      "1          1      MALICE MIZER     274         1        483\n",
      "2          1      MALICE MIZER     785         1         76\n",
      "3          2   Diary of Dreams     135         2       1021\n",
      "4          2   Diary of Dreams     257         2        152\n",
      "...      ...               ...     ...       ...        ...\n",
      "92829  18741    Diamanda Galás     454     18741        301\n",
      "92830  18742            Aya RL     454     18742        294\n",
      "92831  18743       Coptic Rain     454     18743        287\n",
      "92832  18744      Oz Alchemist     454     18744        286\n",
      "92833  18745  Grzegorz Tomczak     585     18745        426\n",
      "\n",
      "[92834 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "plays = pd.read_csv('data/lastfm/user_artists.dat', sep='\\t')\n",
    "artists = pd.read_csv('data/lastfm/artists.dat', sep='\\t', usecols=['id','name'])\n",
    "\n",
    "# Merge artist and user pref data\n",
    "ap = pd.merge(artists, plays, how=\"inner\", left_on=\"id\", right_on=\"artistID\")\n",
    "ap = ap.rename(columns={\"weight\": \"playCount\"})\n",
    "\n",
    "# Group artist by name\n",
    "artist_rank = ap.groupby(['name']) \\\n",
    "    .agg({'userID' : 'count', 'playCount' : 'sum'}) \\\n",
    "    .rename(columns={\"userID\" : 'totalUsers', \"playCount\" : \"totalPlays\"}) \\\n",
    "    .sort_values(['totalPlays'], ascending=False)\n",
    "\n",
    "artist_rank['avgPlays'] = artist_rank['totalPlays'] / artist_rank['totalUsers']\n",
    "#print(artist_rank)\n",
    "print(ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "three-playback",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id             name  userID  artistID  playCount  totalUsers  \\\n",
      "2800      72     Depeche Mode    1642        72     352698         282   \n",
      "35843    792           Thalía    2071       792     324663          26   \n",
      "27302    511               U2    1094       511     320725         185   \n",
      "8152     203             Blur    1905       203     257978         114   \n",
      "26670    498         Paramore    1664       498     227829         399   \n",
      "...      ...              ...     ...       ...        ...         ...   \n",
      "38688    913  Destiny's Child    1810       913          1          83   \n",
      "32955    697              Sia    1290       697          1          56   \n",
      "71811   4988   Chris Spheeris     510      4988          1           5   \n",
      "91319  17080      Haylie Duff    1851     17080          1           1   \n",
      "63982   3201        Kate Bush     344      3201          1          42   \n",
      "\n",
      "       totalPlays      avgPlays  playCountScaled  \n",
      "2800      1301308   4614.567376         1.000000  \n",
      "35843      350035  13462.884615         0.920513  \n",
      "27302      493024   2664.994595         0.909347  \n",
      "8152       318221   2791.412281         0.731441  \n",
      "26670      963449   2414.659148         0.645960  \n",
      "...           ...           ...              ...  \n",
      "38688       34746    418.626506         0.000000  \n",
      "32955       27597    492.803571         0.000000  \n",
      "71811        3106    621.200000         0.000000  \n",
      "91319           1      1.000000         0.000000  \n",
      "63982       17408    414.476190         0.000000  \n",
      "\n",
      "[92834 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge into ap matrix\n",
    "#print(ap)\n",
    "ap = ap.join(artist_rank, on=\"name\", how=\"inner\").sort_values(['playCount'], ascending=False)\n",
    "\n",
    "# Preprocessing\n",
    "pc = ap.playCount\n",
    "play_count_scaled = (pc - pc.min()) / (pc.max() - pc.min())\n",
    "ap = ap.assign(playCountScaled=play_count_scaled)\n",
    "print(ap)\n",
    "\n",
    "# Build a user-artist rating matrix \n",
    "ratings_df = ap.pivot(index='userID', columns='artistID', values='playCountScaled')\n",
    "ratings = ratings_df.fillna(0).values\n",
    "\n",
    "# Show sparsity\n",
    "sparsity = float(len(ratings.nonzero()[0])) / (ratings.shape[0] * ratings.shape[1]) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "exact-basic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.28\n"
     ]
    }
   ],
   "source": [
    "print(\"sparsity: %.2f\" % sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dangerous-forwarding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artistID  1      2         3      4      5         6      7      8      9      \\\n",
      "userID                                                                          \n",
      "2           NaN    NaN       NaN    NaN    NaN       NaN    NaN    NaN    NaN   \n",
      "3           NaN    NaN       NaN    NaN    NaN       NaN    NaN    NaN    NaN   \n",
      "4           NaN    NaN       NaN    NaN    NaN       NaN    NaN    NaN    NaN   \n",
      "5           NaN    NaN       NaN    NaN    NaN       NaN    NaN    NaN    NaN   \n",
      "6           NaN    NaN       NaN    NaN    NaN       NaN    NaN    NaN    NaN   \n",
      "...         ...    ...       ...    ...    ...       ...    ...    ...    ...   \n",
      "2095        NaN    NaN       NaN    NaN    NaN       NaN    NaN    NaN    NaN   \n",
      "2096        NaN    NaN       NaN    NaN    NaN       NaN    NaN    NaN    NaN   \n",
      "2097        NaN    NaN       NaN    NaN    NaN       NaN    NaN    NaN    NaN   \n",
      "2099        NaN    NaN       NaN    NaN    NaN       NaN    NaN    NaN    NaN   \n",
      "2100        NaN    NaN  0.001154    NaN    NaN  0.001143    NaN    NaN    NaN   \n",
      "\n",
      "artistID  10     ...  18736  18737  18738  18739  18740  18741  18742  18743  \\\n",
      "userID           ...                                                           \n",
      "2           NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "3           NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "4           NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "5           NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "6           NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "...         ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "2095        NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "2096        NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "2097        NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "2099        NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "2100        NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "artistID  18744  18745  \n",
      "userID                  \n",
      "2           NaN    NaN  \n",
      "3           NaN    NaN  \n",
      "4           NaN    NaN  \n",
      "5           NaN    NaN  \n",
      "6           NaN    NaN  \n",
      "...         ...    ...  \n",
      "2095        NaN    NaN  \n",
      "2096        NaN    NaN  \n",
      "2097        NaN    NaN  \n",
      "2099        NaN    NaN  \n",
      "2100        NaN    NaN  \n",
      "\n",
      "[1892 rows x 17632 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alpha-investigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating matrix shape (1892, 17632)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Build a sparse matrix\n",
    "X = csr_matrix(ratings)\n",
    "\n",
    "n_users, n_items = ratings_df.shape\n",
    "print(\"rating matrix shape\", ratings_df.shape)\n",
    "\n",
    "user_ids = ratings_df.index.values\n",
    "artist_names = ap.sort_values(\"artistID\")[\"name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "delayed-circle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1892x17632 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 92198 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import auc_score, precision_at_k, recall_at_k\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "# Build data references + train test\n",
    "Xcoo = X.tocoo()\n",
    "data = Dataset()\n",
    "data.fit(np.arange(n_users), np.arange(n_items))\n",
    "interactions, weights = data.build_interactions(zip(Xcoo.row, Xcoo.col, Xcoo.data)) \n",
    "train, test = random_train_test_split(interactions)\n",
    "\n",
    "# Ignore that (weight seems to be ignored...)\n",
    "#train = train_.tocsr()\n",
    "#test = test_.tocsr()\n",
    "#train[train==1] = X[train==1]\n",
    "#test[test==1] = X[test==1]\n",
    "\n",
    "interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-income",
   "metadata": {},
   "source": [
    "### WARP loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "backed-dimension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7eff6ab908e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model = LightFM(learning_rate=0.05, loss='warp')\n",
    "model.fit(train, epochs=10, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "remarkable-forge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.37, test 0.13.\n",
      "Recall: train 0.10, test 0.13.\n",
      "AUC: train 0.96, test 0.85.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10, train_interactions=train).mean()\n",
    "train_recall = recall_at_k(model, train).mean()\n",
    "test_recall = recall_at_k(model, test, train_interactions=train).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test, train_interactions=train).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('Recall: train %.2f, test %.2f.' % (train_recall, test_recall))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "independent-wheat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Beatles' 'Coldplay' 'Depeche Mode' ... 'Krusha' 'ScreamerClauz'\n",
      " 'Peter Kurten']\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "scores = model.predict(0, np.arange(n_items))\n",
    "top_items = artist_names[np.argsort(-scores)]\n",
    "print(top_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-bosnia",
   "metadata": {},
   "source": [
    "# Loss function selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "legal-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(loss):\n",
    "    modelx = LightFM(learning_rate=0.05, loss=loss)\n",
    "    modelx.fit(train, epochs=10, num_threads=2)\n",
    "    train_precisionx = precision_at_k(modelx, train, k=10).mean()\n",
    "    test_precisionx = precision_at_k(modelx, test, k=10, train_interactions=train).mean()\n",
    "    train_recallx = recall_at_k(modelx, train).mean()\n",
    "    test_recallx = recall_at_k(modelx, test, train_interactions=train).mean()\n",
    "    train_aucx = auc_score(modelx, train).mean()\n",
    "    test_aucx = auc_score(modelx, test, train_interactions=train).mean()\n",
    "    scoresx = modelx.predict(0, np.arange(n_items))\n",
    "    top_itemsx = artist_names[np.argsort(-scoresx)]\n",
    "    print(loss,'Precision: \\t\\ttrain %.2f, test %.2f.' % (train_precisionx, test_precisionx))\n",
    "    print(loss,'Recall: \\t\\ttrain %.2f, test %.2f.' % (train_recallx, test_recallx))\n",
    "    print(loss,'AUC: \\t\\t\\ttrain %.2f, test %.2f.' % (train_aucx, test_aucx))\n",
    "    #print(top_itemsx)\n",
    "    return top_itemsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aggressive-politics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warp Precision: \t\ttrain 0.39, test 0.13.\n",
      "warp Recall: \t\ttrain 0.10, test 0.14.\n",
      "warp AUC: \t\t\ttrain 0.97, test 0.86.\n",
      "logistic Precision: \t\ttrain 0.20, test 0.07.\n",
      "logistic Recall: \t\ttrain 0.05, test 0.07.\n",
      "logistic AUC: \t\t\ttrain 0.89, test 0.81.\n",
      "bpr Precision: \t\ttrain 0.36, test 0.12.\n",
      "bpr Recall: \t\ttrain 0.09, test 0.12.\n",
      "bpr AUC: \t\t\ttrain 0.85, test 0.78.\n",
      "warp-kos Precision: \t\ttrain 0.35, test 0.13.\n",
      "warp-kos Recall: \t\ttrain 0.09, test 0.13.\n",
      "warp-kos AUC: \t\t\ttrain 0.89, test 0.82.\n"
     ]
    }
   ],
   "source": [
    "warpitems = get_scores('warp')\n",
    "logitems = get_scores('logistic')\n",
    "bpritems = get_scores('bpr')\n",
    "warpkositems = get_scores('warp-kos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-antarctica",
   "metadata": {},
   "source": [
    "### get_recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bibliographic-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "def get_recommendation(userid):\n",
    "    X = csr_matrix(ratings)\n",
    "    svd = TruncatedSVD(n_components=1000, n_iter=7, random_state=0)\n",
    "    X_matrix_svd = svd.fit_transform(X)\n",
    "    cosine_sim = linear_kernel(X_matrix_svd,X_matrix_svd[userid].reshape(1,-1))\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:51]\n",
    "    user_indices = [i[0] for i in sim_scores]\n",
    "    artist_top = []\n",
    "    for i in user_indices:\n",
    "        idx_i = np.argmax(ratings[i])\n",
    "        if len(ap['name'][ap['artistID'] == idx_i].index)== 1:            \n",
    "            if ap['name'][ap['artistID'] == idx_i].unique()[0] not in artist_top:\n",
    "                artist_top.append( ap['name'][ap['artistID'] == idx_i].unique()[0] )\n",
    "    return artist_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "obvious-stretch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Easybeats',\n",
       " 'Luxuria',\n",
       " 'Bruce Faulconer',\n",
       " 'One Day as a Lion',\n",
       " 'Hellmouth',\n",
       " 'Andrew Lawson',\n",
       " 'Hird',\n",
       " 'Groovie Ghoulies',\n",
       " 'cokiyu',\n",
       " 'James Cotton',\n",
       " 'A Song For You My Dear',\n",
       " 'Multigen',\n",
       " 'Dikers']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendation(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "valuable-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_ground_truth(user)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-mitchell",
   "metadata": {},
   "source": [
    "# Implicit Vs Explicit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-hopkins",
   "metadata": {},
   "source": [
    "Implicit model:\n",
    "\n",
    "All interactions in the training matrix are treated as positive signals, and products that users did not interact with they implicitly do not like. The goal of the model is to score these implicit positives highly while assigining low scores to implicit negatives\n",
    "\n",
    "Explicit model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-hundred",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "broadband-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearchLFM(loss, learning_rate, epoch, score):\n",
    "    res = {}\n",
    "    for l1 in loss:\n",
    "        for lr in learning_rate:\n",
    "            for ep in epoch:\n",
    "                testID = score+'_'+str(l1)+'_'+str(lr)+'_'+str(ep)\n",
    "                modelx = LightFM(learning_rate=lr, loss=l1)\n",
    "                modelx.fit(train, epochs=ep, num_threads=2)\n",
    "                precision = precision_at_k(modelx, train, k=10).mean()\n",
    "                recall = recall_at_k(modelx, train).mean()\n",
    "                auc = auc_score(modelx, train).mean()\n",
    "                \n",
    "                res[testID] = (precision, recall, auc)\n",
    "\n",
    "                if score == 'precision':\n",
    "                    print(testID,' \\t\\t\\t %.2f' % (precision))\n",
    "                elif score == 'recall':\n",
    "                    print(testID,' \\t\\t\\t %.2f' % (recall))\n",
    "                else:\n",
    "                    print(testID,' \\t\\t\\t %.2f' % (auc))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "minute-hotel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_warp_0.01_5  \t\t\t 0.87\n",
      "auc_warp_0.01_10  \t\t\t 0.89\n",
      "auc_warp_0.01_20  \t\t\t 0.90\n",
      "auc_warp_0.05_5  \t\t\t 0.94\n",
      "auc_warp_0.05_10  \t\t\t 0.96\n",
      "auc_warp_0.05_20  \t\t\t 0.98\n",
      "auc_warp_0.1_5  \t\t\t 0.97\n",
      "auc_warp_0.1_10  \t\t\t 0.98\n",
      "auc_warp_0.1_20  \t\t\t 0.99\n",
      "auc_warp_0.2_5  \t\t\t 0.76\n",
      "auc_warp_0.2_10  \t\t\t 0.86\n",
      "auc_warp_0.2_20  \t\t\t 0.86\n",
      "auc_warp-kos_0.01_5  \t\t\t 0.82\n",
      "auc_warp-kos_0.01_10  \t\t\t 0.84\n",
      "auc_warp-kos_0.01_20  \t\t\t 0.85\n",
      "auc_warp-kos_0.05_5  \t\t\t 0.87\n",
      "auc_warp-kos_0.05_10  \t\t\t 0.89\n",
      "auc_warp-kos_0.05_20  \t\t\t 0.90\n",
      "auc_warp-kos_0.1_5  \t\t\t 0.87\n",
      "auc_warp-kos_0.1_10  \t\t\t 0.89\n",
      "auc_warp-kos_0.1_20  \t\t\t 0.90\n",
      "auc_warp-kos_0.2_5  \t\t\t 0.74\n",
      "auc_warp-kos_0.2_10  \t\t\t 0.80\n",
      "auc_warp-kos_0.2_20  \t\t\t 0.83\n",
      "auc_bpr_0.01_5  \t\t\t 0.59\n",
      "auc_bpr_0.01_10  \t\t\t 0.61\n",
      "auc_bpr_0.01_20  \t\t\t 0.71\n",
      "auc_bpr_0.05_5  \t\t\t 0.73\n",
      "auc_bpr_0.05_10  \t\t\t 0.85\n",
      "auc_bpr_0.05_20  \t\t\t 0.91\n",
      "auc_bpr_0.1_5  \t\t\t 0.85\n",
      "auc_bpr_0.1_10  \t\t\t 0.92\n",
      "auc_bpr_0.1_20  \t\t\t 0.95\n",
      "auc_bpr_0.2_5  \t\t\t 0.91\n",
      "auc_bpr_0.2_10  \t\t\t 0.96\n",
      "auc_bpr_0.2_20  \t\t\t 0.97\n"
     ]
    }
   ],
   "source": [
    "result = gridsearchLFM(loss = ['warp','warp-kos','bpr'], learning_rate = [0.01,0.05,0.1,0.2], epoch = [5,10,20], score = 'auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-amateur",
   "metadata": {},
   "source": [
    "precision_bpr_0.1_20  \t\t 0.44\n",
    "\n",
    "recall_bpr_0.1_20  \t\t\t 0.11\n",
    "\n",
    "auc_warp_0.1_20  \t\t\t 0.99"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
